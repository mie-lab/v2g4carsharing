{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e786c914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ninawiedemann/miniconda3/envs/gis/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import geopandas as gpd\n",
    "import time\n",
    "from shapely import wkt\n",
    "import datetime\n",
    "from shapely.geometry import Point\n",
    "font = {'family' : 'Sans',\n",
    "        'size'   : 15}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8300c4be",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a75323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_timestamp = lambda x: time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\").timetuple())\n",
    "\n",
    "def lon_lat_to_geom(data, lon_name=\"LON\", lat_name=\"LAT\"):\n",
    "    geom_col = []\n",
    "    for i, row in data.iterrows():\n",
    "        geom = Point(row[lon_name], row[lat_name])\n",
    "        geom_col.append(geom)\n",
    "    data[\"geom\"] = geom_col\n",
    "    data = gpd.GeoDataFrame(data, geometry=\"geom\")\n",
    "    return data\n",
    "\n",
    "def write_geodataframe(gdf, out_path):\n",
    "    geo_col_name = gdf.geometry.name\n",
    "    df = pd.DataFrame(gdf, copy=True)\n",
    "    df[geo_col_name] = gdf.geometry.apply(wkt.dumps)\n",
    "    df.to_csv(out_path, index=True)\n",
    "    \n",
    "def read_geodataframe(in_path, geom_col=\"geom\"):\n",
    "    df = pd.read_csv(in_path)\n",
    "    df[geom_col] = df[geom_col].apply(wkt.loads)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geom_col)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf437dc",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "This script is partly exploration and partly data cleaning, and the last part of this notebook was used to write the data to our PostgreSQL database.\n",
    "In an intermediate step, the data was saved into a new folder called `data_cleaned`. This folder is created in the following cell.\n",
    "\n",
    "Changes to the data:\n",
    "* Merge monthly csvs of reservations & drop duplicates\n",
    "* Some columns are added that we thought might come in handy later, e.g. the reservation duration.\n",
    "* Convert LON LAT columns to a geopandas geometry and save as a Geodataframe using WKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1ec353",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data_cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e84fc7",
   "metadata": {},
   "source": [
    "## USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356041be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_user = pd.read_csv(\"data/20211213_ethz_person.tsv\", sep=\"\\t\")\n",
    "print(\"Number users\", len(data_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2300c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906bf6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert len(np.unique(data_user[\"PERSON_NO\"])) == len(data_user)\n",
    "for col in [\"AGEGROUP\", \"GENDER\", \"LANGUAGE\", \"ABOGROUP\"]:\n",
    "    sns.countplot(data=data_user, x=col)\n",
    "    if len(np.unique(data_user[col].dropna())) > 4:\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac553e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add geometry\n",
    "geo_frame = lon_lat_to_geom(data_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ca106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add agegroup as an integer\n",
    "age_group = data_user[\"AGEGROUP\"].values\n",
    "age_group = age_group[~pd.isna(age_group)]\n",
    "sorted_groups = np.sort(np.unique(age_group))\n",
    "map_dict = {g: i for i, g in enumerate(sorted_groups)}\n",
    "geo_frame[\"AGEGROUP_int\"] = geo_frame[\"AGEGROUP\"].apply(lambda x: map_dict.get(x, pd.NA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to timestamp\n",
    "geo_frame[\"FIRSTENTRY_TIMESTAMP\"] = geo_frame[\"FIRSTENTRYDATE\"].apply(convert_to_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6628735",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(np.unique(geo_frame[\"PERSON_NO\"])) == len(data_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403d2ab",
   "metadata": {},
   "source": [
    "#### WRITE (and read for test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_geodataframe(geo_frame.set_index(\"PERSON_NO\"), \"data_cleaned/user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_geodataframe(\"data_cleaned/user.csv\").set_index(\"PERSON_NO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329aaa52",
   "metadata": {},
   "source": [
    "## VEHICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cars = pd.read_csv(\"data/20211213_ethz_vehicle.tsv\", sep=\"\\t\")\n",
    "# assert len(np.unique(data_cars[\"VEHICLE_NO\"])) == len(data_cars) \n",
    "# assert wrong -> maybe index is actual vehicle number?? the other one is the type?\n",
    "dropped = data_cars.drop_duplicates()\n",
    "len(data_cars), len(dropped), len(np.unique(data_cars[\"VEHICLE_NO\"])), len(data_cars.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db151b52",
   "metadata": {},
   "source": [
    "#### after removing duplicates, add the count to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f44abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_count = data_cars.groupby(\"VEHICLE_NO\").agg({\"VEHICLE_NO\":\"count\"})\n",
    "vehicle_count.rename(columns={\"VEHICLE_NO\": \"COUNT\"}, inplace=True)\n",
    "data_cars_cleaned = dropped.set_index(\"VEHICLE_NO\").merge(vehicle_count, left_index=True, right_index=True)\n",
    "assert np.sum(data_cars_cleaned[\"COUNT\"]) == len(data_cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a90d2a",
   "metadata": {},
   "source": [
    "#### WRITE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f08f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cars_cleaned.to_csv(\"data_cleaned/vehicle.csv\", index=\"VEHICLE_NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20daed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data_cleaned/vehicle.csv\", index_col=\"VEHICLE_NO\")\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b5f32",
   "metadata": {},
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e2e39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in [\"VEHICLE_CATEGORY\", \"BRAND_NAME\", \"ENERGYTYPEGROUP\", \"ENERGYTYPE\"]:\n",
    "    sns.countplot(data=data_cars, x=col)\n",
    "    if len(np.unique(data_cars[col].dropna())) > 4:\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05810b92",
   "metadata": {},
   "source": [
    "## Booking data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aea7e5",
   "metadata": {},
   "source": [
    "### LOAD ALL DATA\n",
    "(They are split into months, but we merge them here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea7261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_path = \"data/20211213_ethz_reservation\"\n",
    "all_bookings = []\n",
    "for booking_csv in sorted(os.listdir(booking_path)):\n",
    "    next_csv = pd.read_csv(os.path.join(booking_path, booking_csv), sep=\"\\t\")\n",
    "    all_bookings.append(next_csv)\n",
    "all_bookings = pd.concat(all_bookings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_bookings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a4eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(os.listdir(booking_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310abfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_booking = all_bookings.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbfe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_booking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd6d9f",
   "metadata": {},
   "source": [
    "### Exploration (bookings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_sec = (data_booking[\"RESERVATIONTO\"].apply(convert_to_timestamp) - data_booking[\"RESERVATIONFROM\"].apply(convert_to_timestamp)) / 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1635a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(duration_sec[duration_sec<100], bins=100)\n",
    "plt.xlim(0, 100)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Reservation duration (in hours)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18488dd3",
   "metadata": {},
   "source": [
    "### How spontaneous are the booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_booking[[\"SYSCREATEDATE\",\"RESERVATIONFROM\", \"RESERVATIONTO\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_create_timestamp = data_booking[\"SYSCREATEDATE\"].apply(convert_to_timestamp)\n",
    "reservation_from_timestamp = data_booking[\"RESERVATIONFROM\"].apply(convert_to_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db292de",
   "metadata": {},
   "outputs": [],
   "source": [
    "spontaneous = (sys_create_timestamp - reservation_from_timestamp) / 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaaf06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many are less than 0.5 hours before reservation\n",
    "print(f\"{round(sum(spontaneous > -0.5) / len(spontaneous)*100,2)}% of bookings are less than half an our before the reservation period\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb42b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut = spontaneous[spontaneous>-300]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(data_cut[data_cut<2], bins=100)\n",
    "plt.xlim(-300, 10)\n",
    "# plt.yscale(\"log\")\n",
    "plt.xlabel(\"How Spontaneous (in hours)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173add6",
   "metadata": {},
   "source": [
    "#### General plot column distributions again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a73a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in [\"RESERVATIONTYPE\", \"RESERVATIONSTATE\", \"TRIPMODE\", \"VEHICLE_CATEGORY\", \"ENERGYTYPEGROUP\"]:\n",
    "    sns.countplot(data=data_booking, x=col)\n",
    "    if len(np.unique(data_booking[col].dropna())) > 2:\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fraction of oneway\", sum(data_booking[\"TRIPMODE\"].str.contains(\"OneWay\"))/len(data_booking))\n",
    "print(\"Fraction of annulliert\", sum(data_booking[\"RESERVATIONSTATE\"].str.contains(\"annu\"))/len(data_booking))\n",
    "print(\"Fraction of Elektro\", sum(data_booking[\"ENERGYTYPEGROUP\"].dropna().str.contains(\"Electro\"))/len(data_booking))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326423f5",
   "metadata": {},
   "source": [
    "### Add the newly created columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0d7da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_booking[\"DURATION_HOURS\"] = duration_sec\n",
    "data_booking[\"SYS_CREATE_TS\"] = sys_create_timestamp\n",
    "data_booking[\"RESERVATION_FROM_TS\"] = reservation_from_timestamp\n",
    "data_booking[\"CREATED_BEFORE_HOURS\"] = spontaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5089d2e",
   "metadata": {},
   "source": [
    "## Create stations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16405b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_cols = ['BASESTART_NO', 'BASESTART_NAME', 'BASESTART_LAT', 'BASESTART_LON']\n",
    "end_cols = ['BASEEND_NO', 'BASEEND_NAME','BASEEND_LAT', 'BASEEND_LON']\n",
    "\n",
    "data_stations = data_booking[start_cols]\n",
    "rename_dict = {c: c.split(\"_\")[-1] for c in start_cols}\n",
    "data_stations = data_stations.rename(columns=rename_dict)\n",
    "add_end_stations =  data_booking[end_cols]\n",
    "rename_dict = {c: c.split(\"_\")[-1] for c in end_cols}\n",
    "add_end_stations = add_end_stations.rename(columns=rename_dict)\n",
    "data_stations = pd.concat([data_stations, add_end_stations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e630f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_often(x):\n",
    "    uni, counts = np.unique(x, return_counts=True)\n",
    "    return uni[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_final = data_stations.groupby(\"NO\").agg({\"NAME\": \"first\", \"LAT\": most_often, \"LON\": most_often})\n",
    "stations_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c63140",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(stations_final) == len(np.unique(data_booking[\"BASESTART_NO\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_final = lon_lat_to_geom(stations_final)\n",
    "stations_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_final = stations_final.reset_index().rename(columns={\"NO\": \"STATION_NO\"}).set_index(\"STATION_NO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31d475",
   "metadata": {},
   "source": [
    "#### WRITE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ccbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_geodataframe(stations_final, \"data_cleaned/station.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3096b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read for test\n",
    "read_geodataframe(\"data_cleaned/station.csv\").set_index(\"STATION_NO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7008c",
   "metadata": {},
   "source": [
    "#### Exploration for the following problem: Stations have varying longitude and latitude values\n",
    "\n",
    "Check here how high the std is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stations_cleaned = data_stations.groupby(\"NO\").agg({\"NAME\": \"first\", \"LAT\": [\"mean\", \"std\"], \"LON\": [\"mean\", \"std\"]})\n",
    "data_stations_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f49fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "std_too_high = data_stations_cleaned[data_stations_cleaned[\"LAT\"][\"std\"]> 0.001].index\n",
    "critical = data_stations.set_index(\"NO\").loc[std_too_high]\n",
    "critical.groupby(\"NO\").agg({\"LAT\":\"std\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a074a",
   "metadata": {},
   "source": [
    "## Clean and save reservations table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79828673",
   "metadata": {},
   "source": [
    "#### Drop all columns that are part of the vehicle or of the stations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_booking = data_booking.drop(columns=['BRAND_NAME','MODEL_NAME',\"VEHICLE_CATEGORY\",\n",
    "                                          \"BRAND_NAME\", \"ENERGYTYPE\", 'BASESTART_NAME',\n",
    "                                          'BASESTART_LAT', 'BASESTART_LON', 'BASEEND_NAME',\n",
    "                                          'BASEEND_LAT', 'BASEEND_LON'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9886f2",
   "metadata": {},
   "source": [
    "#### Write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_booking.set_index(\"RESERVATION_NO\").to_csv(\"data_cleaned/booking.csv\", index=\"RESERVATION_NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19142949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read for check\n",
    "test = pd.read_csv(\"data_cleaned/booking.csv\", index_col=\"RESERVATION_NO\")\n",
    "print(len(test), len(data_booking), len(data_booking_cleaned))\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b905e6",
   "metadata": {},
   "source": [
    "## Rename columns (convert all columns all lower case)\n",
    "\n",
    "Loaded from data_cleaned folder and saved to the same, overwriting the previous cleaned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06305e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [\"VEHICLE_NO\", \"PERSON_NO\", \"STATION_NO\", \"RESERVATION_NO\"]\n",
    "\n",
    "for df_name, index_name in zip([\"vehicle\", \"user\", \"station\", \"booking\"], indices):\n",
    "\n",
    "    # read\n",
    "    if df_name == \"booking\" or df_name==\"vehicle\":\n",
    "        df = pd.read_csv(f\"data_cleaned/{df_name}.csv\", index_col = index_name)\n",
    "    else:\n",
    "        df = read_geodataframe(f\"data_cleaned/{df_name}.csv\").set_index(index_name)\n",
    "    \n",
    "    # modify columns\n",
    "    new_names = {name:name.lower() for name in df.reset_index().columns}\n",
    "    if df_name==\"vehicle\":\n",
    "        new_names[\"COUNT\"] = \"entries_count\"\n",
    "    elif df_name == \"booking\":\n",
    "        new_names[\"BASESTART_NO\"] = \"start_station_no\"\n",
    "        new_names[\"BASEEND_NO\"] = \"end_station_no\"\n",
    "    df = df.reset_index().rename(columns=new_names).set_index(index_name.lower())\n",
    "    \n",
    "    # write\n",
    "    if df_name == \"booking\" or df_name==\"vehicle\":\n",
    "        df.to_csv(f\"data_cleaned/{df_name}.csv\", index=index_name.lower())\n",
    "    else:\n",
    "        write_geodataframe(df, f\"data_cleaned/{df_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d89aa5",
   "metadata": {},
   "source": [
    "## Further processing of reservations:\n",
    "\n",
    "### Split into several parts: Service reservations, cancelled, outliers and final clean reservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf097f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_booking = pd.read_csv(\"data_cleaned/booking.csv\", index_col=\"reservation_no\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543654a3",
   "metadata": {},
   "source": [
    "#### 1) service reservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reservation = data_booking[data_booking[\"reservationtype\"]!=\"Normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reservation.to_csv(os.path.join(\"data_cleaned\", \"service_reservation.csv\"), index=\"reservation_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d47c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it not only includes service but also \"BC-upload\"\n",
    "service_reservation[\"reservationtype\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce booking data to the rest\n",
    "data_booking = data_booking[data_booking[\"reservationtype\"]==\"Normal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9326be1",
   "metadata": {},
   "source": [
    "#### 2) Cancelled bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d17341",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_booking), len(service_reservation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are rows where there is a canceldate, but reservationstate is not \"annulliert\" and everything else looks normal\n",
    "# only 44 rows, so we just ignore that and delete it from the data\n",
    "cond1 = ~pd.isna(data_booking[\"canceldate\"])\n",
    "cond2 = data_booking[\"reservationstate\"]!= \"annulliert\"\n",
    "data_booking[cond1 & cond2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ef82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_cancelled = ~pd.isna(data_booking[\"canceldate\"]) | (data_booking[\"reservationstate\"] == \"sofortige Rückgabe\") | (data_booking[\"reservationstate\"] == \"annulliert\")\n",
    "canceled_bookings = data_booking[cond_cancelled]\n",
    "canceled_bookings.to_csv(os.path.join(\"data_cleaned\", \"cancelled_reservation.csv\"), index=\"reservation_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb85b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to rest\n",
    "data_booking = data_booking[~cond_cancelled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e87725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leftover: abgeschlossen, erfasst, geändert\n",
    "np.unique(data_booking[\"reservationstate\"].values, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb5eb8b",
   "metadata": {},
   "source": [
    "#### 3) TODO: outliers ( only bookings that are too long etc) --> currently not filtered out in reservation.csv\n",
    "Open questions: bookings that are too short? free floating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers are the ones that start much earlier \n",
    "# TODO: outliers are the ones with more than 7 days of booking (168h) - delete or not??\n",
    "# why not: because they might be relevant \n",
    "cond_outlier = data_booking[\"reservationfrom\"] < \"2019\" # data_booking[\"duration_hours\"] > 168\n",
    "outlier_bookings = data_booking[cond_outlier]\n",
    "outlier_bookings.to_csv(os.path.join(\"data_cleaned\", \"outlier_reservation.csv\"), index=\"reservation_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ac980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CODE to check what columns contain zeros and what might be other outliers\n",
    "data_booking.columns #[data_booking[\"duration_hours\"]<.1]\n",
    "# np.unique(data_booking[\"reservationtype\"].values, return_counts=True)\n",
    "for col in data_booking.columns:\n",
    "    if any(pd.isna(data_booking[col])):\n",
    "        print(col)\n",
    "    #[pd.isna(data_booking)]\n",
    "data_booking[pd.isna(data_booking[\"drive_km\"])][[\"drive_km\", \"drive_firststart\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2927ef",
   "metadata": {},
   "source": [
    "#### 4) save the leftover part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76511bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_booking = data_booking[~cond_outlier]\n",
    "data_booking.to_csv(os.path.join(\"data_cleaned\", \"reservation.csv\"), index=\"reservation_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80343e99",
   "metadata": {},
   "source": [
    "## New data: Vehicle to base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b5adc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../../data/V2G4Carsharing/20220204_eth_vehicle_to_base.xlsx\"\n",
    "v2b = pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbc5efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {name:name.lower() for name in v2b.reset_index().columns}\n",
    "new_names[\"BASE_NO\"] = \"station_no\"\n",
    "v2b.rename(columns=new_names, inplace=True)\n",
    "\n",
    "BASE_DATE = pd.to_datetime('2019-01-01 00:00:00.000')\n",
    "FINAL_DATE = pd.to_datetime(\"2020-07-31 23:59:59.999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "279043a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2b_in_range = v2b[(v2b[\"bizbeg\"] <= FINAL_DATE) & (v2b[\"bizend\"] > BASE_DATE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9cf33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2b_in_range.to_csv(\"../data_cleaned/vehicle_to_base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8113c25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23363"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v2b_in_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "938844bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2b_in_range.index.name = \"v2b_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4406393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v2b_id'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2b_in_range.index.name.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed795e01",
   "metadata": {},
   "source": [
    "## Write to PostgreSQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec0d08c",
   "metadata": {},
   "source": [
    "### First run in pgAdmin:\n",
    "\n",
    "CREATE EXTENSION postgis;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649392e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../../goeco_login.json\", \"r\") as infile:\n",
    "    db_credentials = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839dfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "def get_con():\n",
    "    return psycopg2.connect(**db_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35ce3d",
   "metadata": {},
   "source": [
    "### 1) Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd0e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = pd.read_csv(\"data_cleaned/vehicle.csv\", index_col=\"vehicle_no\")\n",
    "vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b153ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://', creator=get_con)\n",
    "vehicles.to_sql(\"vehicle\", engine, schema=\"mobility\", index=True, index_label=\"vehicle_no\", chunksize=10000)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6a689",
   "metadata": {},
   "source": [
    "### 2) Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea2ddc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user = read_geodataframe(\"data_cleaned/user.csv\").set_index(\"person_no\")\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_table_query =  \"CREATE TABLE IF NOT EXISTS mobility.user\\\n",
    "#     (person_no SERIAL PRIMARY KEY, agegroup VARCHAR, gender CHAR,\\\n",
    "#     lat FLOAT, lon FLOAT, language VARCHAR, abogroup VARCHAR, firstentrydate DATETIME,\\\n",
    "#     age_group_int INT, firstentry_timestamp BIGINT)\"\n",
    "# execute_query(create_table_query)\n",
    "\n",
    "#  dtype = {\"person_no\": \"SERIAL PRIMARY KEY\", \n",
    "#       \"agegroup\": \"VARCHAR\",\n",
    "#       \"gender\" : \"CHAR\",\n",
    "#       \"lat\" : \"FLOAT\",\n",
    "#       \"lon\" : \"FLOAT\",\n",
    "#       \"language\" : \"VARCHAR\",\n",
    "#       \"abogroup\" : \"VARCHAR\",\n",
    "#       \"firstentrydate\" : \"DATETIME\",\n",
    "#       \"agegroup_int\" : \"INT\",\n",
    "#       \"firstentry_timestamp\" : \"BIGINT\"\n",
    "#          }         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19778d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://', creator=get_con)\n",
    "user.to_postgis(\"user\", engine, schema=\"mobility\", index=True, index_label=\"person_no\", chunksize=10000, dtype=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c14bb",
   "metadata": {},
   "source": [
    "#### There are a lot of warnings, the reason is simply that geom is NaN for some users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "user[pd.isna(user[\"lat\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c5a6fc",
   "metadata": {},
   "source": [
    "### 3) Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = read_geodataframe(\"data_cleaned/station.csv\").set_index(\"station_no\")\n",
    "station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f77d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = psycopg2.connect(**db_credentials)\n",
    "# dtype = {\"station_no\": \"SERIAL PRIMARY KEY\", \n",
    "#           \"name\": \"VARCHAR\",\n",
    "#           \"lat\" : \"FLOAT\",\n",
    "#           \"lon\" : \"FLOAT\",\n",
    "#           \"geom\": \"POINT\"\n",
    "#           https://stackoverflow.com/questions/38361336/write-geodataframe-into-sql-database\n",
    "#          }\n",
    "engine = create_engine('postgresql+psycopg2://', creator=get_con)\n",
    "station.to_postgis(\"station\", engine, schema=\"mobility\", index=True, index_label=\"station_no\", chunksize=10000)\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec6066",
   "metadata": {},
   "source": [
    "### 4) service reservations (relocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reservation = pd.read_csv(\"data_cleaned/service_reservation.csv\").set_index(\"reservation_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://', creator=get_con)\n",
    "service_reservation.to_sql(\"service_reservation\", engine, schema=\"mobility\", index=True, index_label=\"reservation_no\", chunksize=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c60c9",
   "metadata": {},
   "source": [
    "### 5) cancelled reservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelled_reservation = pd.read_csv(\"data_cleaned/cancelled_reservation.csv\").set_index(\"reservation_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5712f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://', creator=get_con)\n",
    "cancelled_reservation.to_sql(\"cancelled_reservation\", engine, schema=\"mobility\", index=True, index_label=\"reservation_no\", chunksize=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b315dd7",
   "metadata": {},
   "source": [
    "### 6) cleaned reservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reservation = pd.read_csv(\"data_cleaned/reservation.csv\").set_index(\"reservation_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://', creator=get_con)\n",
    "reservation.to_sql(\"reservations\", engine, schema=\"mobility\", index=True, if_exists = 'replace', index_label=\"reservation_no\", chunksize=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1986e45",
   "metadata": {},
   "source": [
    "### OLD VERSION: all bookings at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492de77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "booking = pd.read_csv(\"data_cleaned/booking.csv\").set_index(\"reservation_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f251e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0223070",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://', creator=get_con)\n",
    "booking.to_sql(\"reservation\", engine, schema=\"mobility\", index=True, index_label=\"reservation_no\", chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dffdba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
